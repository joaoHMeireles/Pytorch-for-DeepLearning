{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31600ee-7c31-45b6-b36f-246f63cb48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422c3d3-9661-49d1-85d1-48a9d810308b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Creating simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03331a36-4f64-46be-880e-52e6d02e1655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "X[:10] , y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d33bc5-4608-44b2-9d12-6c776e18de9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388d069-c0bd-47ec-b91f-e826e623396c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Splitting data into training and tests sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b18349-405e-44c8-8437-904a7fe3b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e74a24e-6b41-4a41-9b01-cc25c3bd1ba2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800],\n",
       "         [0.2000],\n",
       "         [0.2200],\n",
       "         [0.2400],\n",
       "         [0.2600],\n",
       "         [0.2800],\n",
       "         [0.3000],\n",
       "         [0.3200],\n",
       "         [0.3400],\n",
       "         [0.3600],\n",
       "         [0.3800],\n",
       "         [0.4000],\n",
       "         [0.4200],\n",
       "         [0.4400],\n",
       "         [0.4600],\n",
       "         [0.4800],\n",
       "         [0.5000],\n",
       "         [0.5200],\n",
       "         [0.5400],\n",
       "         [0.5600],\n",
       "         [0.5800],\n",
       "         [0.6000],\n",
       "         [0.6200],\n",
       "         [0.6400],\n",
       "         [0.6600],\n",
       "         [0.6800],\n",
       "         [0.7000],\n",
       "         [0.7200],\n",
       "         [0.7400],\n",
       "         [0.7600],\n",
       "         [0.7800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260],\n",
       "         [0.4400],\n",
       "         [0.4540],\n",
       "         [0.4680],\n",
       "         [0.4820],\n",
       "         [0.4960],\n",
       "         [0.5100],\n",
       "         [0.5240],\n",
       "         [0.5380],\n",
       "         [0.5520],\n",
       "         [0.5660],\n",
       "         [0.5800],\n",
       "         [0.5940],\n",
       "         [0.6080],\n",
       "         [0.6220],\n",
       "         [0.6360],\n",
       "         [0.6500],\n",
       "         [0.6640],\n",
       "         [0.6780],\n",
       "         [0.6920],\n",
       "         [0.7060],\n",
       "         [0.7200],\n",
       "         [0.7340],\n",
       "         [0.7480],\n",
       "         [0.7620],\n",
       "         [0.7760],\n",
       "         [0.7900],\n",
       "         [0.8040],\n",
       "         [0.8180],\n",
       "         [0.8320],\n",
       "         [0.8460]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3060b2-3305-46ad-9255-a64adf9373f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Building a function to visualize outr data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da5b416f-321d-43a3-9374-57acb06d2cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=None):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "    \n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "    \n",
    "    plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1146c997-9a13-4ade-b713-dd880f510068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "   # plot_predictions();\n",
    "#except Exception as error:\n",
    "    #print(\"Deu merda como era previsto: \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e834575-fb09-481a-9af7-24f4842221ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Creating a model for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab250dc1-3338-476b-be8e-30f198223f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd9be833-ce22-4b38-a090-5aa421a5f123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c83467fe-518d-4b58-8312-cbf9c4b91514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f44b2af1-b7ed-444a-a377-a5b99fd3e340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objetivo: fazer os parâmetros ali de cima virar esses valores aqui de baixo por meio do aprendizado de máquina\n",
    "weight , bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b165ebf-5337-46f0-ae49-4b08890bce81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Making predictions with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14621c5f-3e36-4434-a0ad-8d95a81a9e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3982],\n",
       "        [0.4049],\n",
       "        [0.4116],\n",
       "        [0.4184],\n",
       "        [0.4251],\n",
       "        [0.4318],\n",
       "        [0.4386],\n",
       "        [0.4453],\n",
       "        [0.4520],\n",
       "        [0.4588]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode(): # turns off the gradient tracking in the model\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b552d904-716a-49b9-a446-fd8215be4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ec6fc-49eb-43bd-83a4-cc5a04bdfd81",
   "metadata": {},
   "source": [
    "##### Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "329d7746-020d-47cf-ad7d-ec07f2fb4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optmizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e318d887-9779-45a8-95c3-bb404e0c98a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4394])), ('bias', tensor([0.3653]))])\n",
      "tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4425])), ('bias', tensor([0.3688]))])\n",
      "tensor(0.0564, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4455])), ('bias', tensor([0.3718]))])\n",
      "tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4483])), ('bias', tensor([0.3743]))])\n",
      "tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4512])), ('bias', tensor([0.3768]))])\n",
      "tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4539])), ('bias', tensor([0.3788]))])\n",
      "tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4564])), ('bias', tensor([0.3803]))])\n",
      "tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4590])), ('bias', tensor([0.3818]))])\n",
      "tensor(0.0490, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4615])), ('bias', tensor([0.3833]))])\n",
      "tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4639])), ('bias', tensor([0.3843]))])\n",
      "tensor(0.0475, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4662])), ('bias', tensor([0.3853]))])\n",
      "tensor(0.0469, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4684])), ('bias', tensor([0.3858]))])\n",
      "tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4706])), ('bias', tensor([0.3863]))])\n",
      "tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4728])), ('bias', tensor([0.3868]))])\n",
      "tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4748])), ('bias', tensor([0.3868]))])\n",
      "tensor(0.0450, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4768])), ('bias', tensor([0.3868]))])\n",
      "tensor(0.0446, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4788])), ('bias', tensor([0.3868]))])\n",
      "tensor(0.0442, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4808])), ('bias', tensor([0.3868]))])\n",
      "tensor(0.0438, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4828])), ('bias', tensor([0.3868]))])\n",
      "tensor(0.0434, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4848])), ('bias', tensor([0.3868]))])\n",
      "tensor(0.0431, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4866])), ('bias', tensor([0.3863]))])\n",
      "tensor(0.0427, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4884])), ('bias', tensor([0.3858]))])\n",
      "tensor(0.0424, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4902])), ('bias', tensor([0.3853]))])\n",
      "tensor(0.0420, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4920])), ('bias', tensor([0.3848]))])\n",
      "tensor(0.0417, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4938])), ('bias', tensor([0.3843]))])\n",
      "tensor(0.0413, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4956])), ('bias', tensor([0.3838]))])\n",
      "tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4974])), ('bias', tensor([0.3833]))])\n",
      "tensor(0.0406, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.4992])), ('bias', tensor([0.3828]))])\n",
      "tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5010])), ('bias', tensor([0.3823]))])\n",
      "tensor(0.0399, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5028])), ('bias', tensor([0.3818]))])\n",
      "tensor(0.0396, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5046])), ('bias', tensor([0.3813]))])\n",
      "tensor(0.0392, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5064])), ('bias', tensor([0.3808]))])\n",
      "tensor(0.0389, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5082])), ('bias', tensor([0.3803]))])\n",
      "tensor(0.0385, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5100])), ('bias', tensor([0.3798]))])\n",
      "tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5116])), ('bias', tensor([0.3788]))])\n",
      "tensor(0.0379, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5134])), ('bias', tensor([0.3783]))])\n",
      "tensor(0.0375, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5152])), ('bias', tensor([0.3778]))])\n",
      "tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5168])), ('bias', tensor([0.3768]))])\n",
      "tensor(0.0368, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5186])), ('bias', tensor([0.3763]))])\n",
      "tensor(0.0365, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5202])), ('bias', tensor([0.3753]))])\n",
      "tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5220])), ('bias', tensor([0.3748]))])\n",
      "tensor(0.0358, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5236])), ('bias', tensor([0.3738]))])\n",
      "tensor(0.0354, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5254])), ('bias', tensor([0.3733]))])\n",
      "tensor(0.0351, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5272])), ('bias', tensor([0.3728]))])\n",
      "tensor(0.0348, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5288])), ('bias', tensor([0.3718]))])\n",
      "tensor(0.0344, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5306])), ('bias', tensor([0.3713]))])\n",
      "tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5322])), ('bias', tensor([0.3703]))])\n",
      "tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5340])), ('bias', tensor([0.3698]))])\n",
      "tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5355])), ('bias', tensor([0.3688]))])\n",
      "tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5373])), ('bias', tensor([0.3683]))])\n",
      "tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5391])), ('bias', tensor([0.3678]))])\n",
      "tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5407])), ('bias', tensor([0.3668]))])\n",
      "tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5425])), ('bias', tensor([0.3663]))])\n",
      "tensor(0.0317, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5441])), ('bias', tensor([0.3653]))])\n",
      "tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5459])), ('bias', tensor([0.3648]))])\n",
      "tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5475])), ('bias', tensor([0.3638]))])\n",
      "tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5493])), ('bias', tensor([0.3633]))])\n",
      "tensor(0.0303, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5509])), ('bias', tensor([0.3623]))])\n",
      "tensor(0.0300, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5527])), ('bias', tensor([0.3618]))])\n",
      "tensor(0.0296, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5545])), ('bias', tensor([0.3613]))])\n",
      "tensor(0.0293, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5561])), ('bias', tensor([0.3603]))])\n",
      "tensor(0.0289, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5579])), ('bias', tensor([0.3598]))])\n",
      "tensor(0.0286, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5595])), ('bias', tensor([0.3588]))])\n",
      "tensor(0.0282, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5613])), ('bias', tensor([0.3583]))])\n",
      "tensor(0.0279, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5629])), ('bias', tensor([0.3573]))])\n",
      "tensor(0.0275, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5647])), ('bias', tensor([0.3568]))])\n",
      "tensor(0.0272, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5665])), ('bias', tensor([0.3563]))])\n",
      "tensor(0.0269, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5681])), ('bias', tensor([0.3553]))])\n",
      "tensor(0.0265, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5699])), ('bias', tensor([0.3548]))])\n",
      "tensor(0.0262, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5715])), ('bias', tensor([0.3538]))])\n",
      "tensor(0.0258, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5733])), ('bias', tensor([0.3533]))])\n",
      "tensor(0.0255, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5748])), ('bias', tensor([0.3523]))])\n",
      "tensor(0.0251, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5766])), ('bias', tensor([0.3518]))])\n",
      "tensor(0.0248, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5784])), ('bias', tensor([0.3513]))])\n",
      "tensor(0.0245, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5800])), ('bias', tensor([0.3503]))])\n",
      "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5818])), ('bias', tensor([0.3498]))])\n",
      "tensor(0.0238, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5834])), ('bias', tensor([0.3488]))])\n",
      "tensor(0.0234, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5852])), ('bias', tensor([0.3483]))])\n",
      "tensor(0.0231, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5868])), ('bias', tensor([0.3473]))])\n",
      "tensor(0.0227, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5886])), ('bias', tensor([0.3468]))])\n",
      "tensor(0.0224, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5902])), ('bias', tensor([0.3458]))])\n",
      "tensor(0.0221, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5920])), ('bias', tensor([0.3453]))])\n",
      "tensor(0.0217, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5938])), ('bias', tensor([0.3448]))])\n",
      "tensor(0.0214, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5954])), ('bias', tensor([0.3438]))])\n",
      "tensor(0.0210, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5972])), ('bias', tensor([0.3433]))])\n",
      "tensor(0.0207, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.5988])), ('bias', tensor([0.3423]))])\n",
      "tensor(0.0203, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6006])), ('bias', tensor([0.3418]))])\n",
      "tensor(0.0200, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6022])), ('bias', tensor([0.3408]))])\n",
      "tensor(0.0196, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6040])), ('bias', tensor([0.3403]))])\n",
      "tensor(0.0193, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6058])), ('bias', tensor([0.3398]))])\n",
      "tensor(0.0190, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6074])), ('bias', tensor([0.3388]))])\n",
      "tensor(0.0186, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6092])), ('bias', tensor([0.3383]))])\n",
      "tensor(0.0183, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6108])), ('bias', tensor([0.3373]))])\n",
      "tensor(0.0179, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6126])), ('bias', tensor([0.3368]))])\n",
      "tensor(0.0176, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6141])), ('bias', tensor([0.3358]))])\n",
      "tensor(0.0172, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6159])), ('bias', tensor([0.3353]))])\n",
      "tensor(0.0169, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6175])), ('bias', tensor([0.3343]))])\n",
      "tensor(0.0166, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6193])), ('bias', tensor([0.3338]))])\n",
      "tensor(0.0162, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6211])), ('bias', tensor([0.3333]))])\n",
      "tensor(0.0159, grad_fn=<MeanBackward0>)\n",
      "OrderedDict([('weights', tensor([0.6227])), ('bias', tensor([0.3323]))])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# training loop\n",
    "epochs = 100 # one loop through the data\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_0.train() # sets all parameters that require gradient to require gradient\n",
    "    \n",
    "    y_pred = model_0(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    print(loss)\n",
    "    \n",
    "    optmizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optmizer.step()\n",
    "    \n",
    "    model_0.eval() # turns off gradient tracking\n",
    "    \n",
    "    print(model_0.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "042b9a75-c552-4152-a5d9-0daf289a808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds_new = model_0(X_test)\n",
    "#     plot_predictions(prediction=y_preds_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2710d54-fc14-4f19-96d0-7060e8aaa269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight , bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc987d9e-5be1-429e-8f97-54c019befea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f7387-23d4-4856-a5a8-b9a25d0fbaca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea951f7d-c1e8-45cd-9a78-c4f1a4ea4eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e58126c-1247-47fc-8335-30f3110bd3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e1aa6-fe1f-4a7c-a121-d4c5939d053e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b9cd12-d4b5-4a0e-b520-baed064949a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b0c9a-cc45-4c24-8fda-590cb9a0a8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cb4bd78-beff-49d2-8ba8-60b00bdee913",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821bb8f-eb24-463c-9608-12079b33f622",
   "metadata": {},
   "source": [
    "##### PyTorch model uilding essentials\n",
    "\n",
    "* torch.nn - contains all of the buildings for computational graphs\n",
    "* torch.nn.Parameter - what parameters should our model try and learn\n",
    "* torch.nn.Module - the base class for all neural network modules\n",
    "* torch.optim - this is where the optmizers in PyTorch live\n",
    "* def forward() - all nn.Module subclasses require you to overwrite forward(). This method defines what happens in the forward computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a66be2-9d57-4b30-991e-2ea0ea69e226",
   "metadata": {},
   "source": [
    "##### Things we need to train:\n",
    "\n",
    "* Loss function: calculate how wrong the predctions were\n",
    "* Optmizer: get the loss and adjust the parameters\n",
    "\n",
    "For PyTorch we need:\n",
    "\n",
    "* a training loop\n",
    "* a test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2551de9d-48ec-4f6e-bd53-b1f4595da367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
