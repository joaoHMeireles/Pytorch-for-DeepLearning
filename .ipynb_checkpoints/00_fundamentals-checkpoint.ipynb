{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54bcb01-c9b4-4042-8e8a-93fd928dc636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d57194-2398-492b-a5c2-a25427581621",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Types os tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22952d4-3cdf-42da-b639-ca82975871b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff833694-3f8a-4b1a-855e-1d80c3b59dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e83c8ec7-30b8-484c-b910-9302f27f2243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b702c1-691f-4765-b92a-20cdffe90eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da3921-832c-4ab3-abf0-64cd71b338a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "370f2a9f-c564-481a-afe7-0144d39476f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb040b42-5355-47ea-8e03-e765664c1dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2dce6f-5649-49bc-8a00-3962468e3ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e66c01-a566-45da-a119-3e4d5d629a90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37e0a62-20d3-4d0e-b200-99a7fbc3e204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[7,8], [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c27c9904-9d11-4ddd-9034-436636744bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f2285a-febd-4bad-9933-39f45d3ca8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd88a1-3e4b-4637-85cf-5112d8893766",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0dd7c9f-9552-4063-9ad3-4fdc31152d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1,2], [3,4]], \n",
    "                       [[5,6], [7,8]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f29f658f-0120-4528-b39c-5058f81e4707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "859364ca-c913-4ba5-af2b-977dd86d7673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862f3540-545e-4ca3-b72b-9229e11ae410",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edc364bc-2e70-4c6e-b83d-b00f3f8f343a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7630, 0.9168, 0.3308, 0.0354],\n",
       "        [0.3795, 0.5185, 0.6589, 0.5682],\n",
       "        [0.1772, 0.0017, 0.3656, 0.1613]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2cc01ee-bf00-4f2a-8bba-2b3a67921b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b090c972-6f09-4661-8f88-0fe0f62ae791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9717, 0.5931, 0.1748],\n",
       "         [0.3841, 0.9394, 0.9007],\n",
       "         [0.5885, 0.7598, 0.5010],\n",
       "         ...,\n",
       "         [0.0915, 0.9817, 0.0233],\n",
       "         [0.7789, 0.1419, 0.9487],\n",
       "         [0.5457, 0.0744, 0.1609]],\n",
       "\n",
       "        [[0.4202, 0.0645, 0.4187],\n",
       "         [0.7220, 0.4268, 0.9817],\n",
       "         [0.1075, 0.8041, 0.7312],\n",
       "         ...,\n",
       "         [0.2482, 0.3429, 0.4404],\n",
       "         [0.4627, 0.8105, 0.8591],\n",
       "         [0.7692, 0.8985, 0.7398]],\n",
       "\n",
       "        [[0.4899, 0.3898, 0.1054],\n",
       "         [0.5410, 0.4060, 0.1352],\n",
       "         [0.1200, 0.2725, 0.5664],\n",
       "         ...,\n",
       "         [0.1076, 0.4442, 0.1433],\n",
       "         [0.7298, 0.5507, 0.3358],\n",
       "         [0.3275, 0.2123, 0.5949]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0197, 0.2839, 0.3324],\n",
       "         [0.0768, 0.7752, 0.9452],\n",
       "         [0.9990, 0.0898, 0.0371],\n",
       "         ...,\n",
       "         [0.8042, 0.1613, 0.3352],\n",
       "         [0.6282, 0.1700, 0.0762],\n",
       "         [0.0844, 0.5975, 0.9787]],\n",
       "\n",
       "        [[0.4254, 0.7306, 0.8446],\n",
       "         [0.3728, 0.9094, 0.1244],\n",
       "         [0.0289, 0.4535, 0.8376],\n",
       "         ...,\n",
       "         [0.8733, 0.9558, 0.9811],\n",
       "         [0.9303, 0.7970, 0.5984],\n",
       "         [0.3590, 0.0308, 0.1867]],\n",
       "\n",
       "        [[0.9029, 0.5713, 0.6940],\n",
       "         [0.0768, 0.6610, 0.1371],\n",
       "         [0.6291, 0.7009, 0.1124],\n",
       "         ...,\n",
       "         [0.6726, 0.6297, 0.8653],\n",
       "         [0.5689, 0.6985, 0.9063],\n",
       "         [0.2848, 0.4825, 0.9337]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor = torch.rand(size=(224,224,3))\n",
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de745c7f-b9cd-474a-8d67-99d1305a12fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65919d7d-9a72-40ce-947a-6be10fbd971b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c89cd9-f5bf-424d-a22e-b06cb80eb441",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fc93440-9e93-464b-b816-d90c060441a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(3,4)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "742f3258-5535-43c2-96fa-5f3ac92ac6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(3,4)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c59e83ba-5866-4fec-a4ef-06ed6708f767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5df0f0-eaa3-4770-8ec7-ddb3579db21c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Tensors in a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5efc9a1b-4c16-4520-89ad-7ecaff649b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fc0092f-d78d-4deb-8be8-589baccc3948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros = torch.zeros_like(one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30001f4f-0498-44f8-87bd-9870ae0f7a2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ab8bf5f-5b76-4649-8d64-e08f93437df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0,6.0,9.0], \n",
    "                               dtype=None, # what datatype is the tensor\n",
    "                               device=None, # what device is your tensor on(cuda,...)\n",
    "                               requires_grad=False #track the gradients or not\n",
    "                               )\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92108857-869a-470c-9364-4dbc750d798a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4452cb28-f4a6-4fef-94aa-a7e489a8c13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67f2b7ff-3f93-4bd5-a141-fee0089b3d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bc5152e-a7b4-4c23-b067-f6046cb45cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e72dfb6f-b105-481a-be01-5a0bde805ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d96714-72e3-4356-a853-1a7c4ba84f50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Tensor attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d509f22-72ea-437f-b2ef-9503de489a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1591, 0.3242, 0.5843, 0.1485],\n",
       "        [0.2063, 0.9466, 0.3882, 0.8970],\n",
       "        [0.7909, 0.3155, 0.9829, 0.3380]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80c520c5-bc56-4c96-b63d-a56b36cff9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b78e80a-f49a-45d8-a570-31b612e5d500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "390eaa3f-1acd-4f9e-955b-b95accad16ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575063d8-8b89-4792-9669-6d8597fa9f5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Manipulating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dce547a-a821-414c-81ab-036f3ad3de2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20431509-d941-4e57-8b86-d3a87e9771d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5696a9ad-fbdf-4c1b-af50-0399f4cc9875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e421e5e7-51db-455c-bedc-9ccdfa4c9f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cae08c0-f6a5-407c-8795-ddc8a3b31c7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b8ac767-7115-4f3f-b636-57a0406c9da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7639c27-e422-4bc7-b830-93e2710b250d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2a83ede-ae7e-4421-8128-6d0605c3afb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.subtract(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39a77021-ec00-4222-8462-64b1673bef6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.divide(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cddb7e-4ac2-45ca-b9d1-12d57770853f",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba24b4af-51bf-4dc9-9e34-4500815c45bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4706b7dc-d951-4d19-8c68-39048b6cc1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea7f8b98-e08f-414a-a68f-e941313d2260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deu merda como era previsto:  mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.matmul( torch.rand(3,2) , torch.rand(3,2))\n",
    "\n",
    "except Exception as error:\n",
    "    print(\"Deu merda como era previsto: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5179bf66-ece3-41a5-9dbb-2b5079553bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7079, 0.9667, 0.4256],\n",
       "        [0.5829, 0.9188, 0.4513],\n",
       "        [0.3329, 0.6950, 0.3975]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul( torch.rand(3,2) , torch.rand(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aadcb300-af6c-457b-a80e-55dd26d12227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1478, 0.8503],\n",
       "        [0.4953, 1.1901]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul( torch.rand(2,3) , torch.rand(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d733fa3-4666-4f57-9ac4-890b4b99f437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 23,  29,  35],\n",
       "        [ 53,  67,  81],\n",
       "        [ 83, 105, 127]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1,2],\n",
    "                         [3,4],\n",
    "                         [5,6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,8],\n",
    "                        [9,10],\n",
    "                        [11,12]])\n",
    "\n",
    "tensor_B = tensor_B.T #Transpose\n",
    "\n",
    "torch.mm(tensor_A, tensor_B) # same as torch.matmul()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b6540-b0b8-4c12-8dda-b91223c2235f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Tensor aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62783afa-94e2-4920-b4a2-220abd4724e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27b0dfa1-a81c-44e9-ae9b-d538ce5d8ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x) , x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1ff4a3f-d4b6-4ed5-964c-e892a6267a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x) , x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cb0c97e-fa8a-442e-804d-9c1f5b28398e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because the mean function subject needs to be a float\n",
    "torch.mean(x, dtype=torch.float32) , x.type(torch.float32).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32c146fd-a8c3-4dd0-a992-88ff839392e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x) , x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acf1a484-76c7-4e00-8abe-48ca4e02c26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the position of the lowest value inside the tensor\n",
    "torch.argmin(x) , x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d883de4-66eb-457c-b4ea-cf838e92b0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(9))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the position of the highest value inside the tensor\n",
    "torch.argmax(x) , x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913a988-8c90-44b0-a00c-d1c8682a1773",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Reshaping, viewing, stacking, squeezing and unsqueezing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5cc14fc5-40d3-42a6-8490-acdda9c34f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(1., 10.)\n",
    "y , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90790b34-218f-43bd-8a2b-780f946c1cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48787767-c354-47ea-bd88-acd785b6547a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.],\n",
       "        [9.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(9,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "653b5e15-0455-45e6-a8b2-ca0d88b67966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3827bca-b094-4c30-89e6-bec89430ca3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a copy\n",
    "y_reshaped = y.reshape(1,9)\n",
    "y_reshaped , y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74bc3a31-4b96-40fb-81a5-0fe0d31d0e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# share the same memory\n",
    "z = y.view(1,9)\n",
    "z , z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f09b099-2490-4b51-8941-de5aab5ed477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:,0] = 5\n",
    "z, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c9af5f6a-fb64-4a82-9d82-f503b194650b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_stacked = torch.stack([y,y,y,y], dim=0)\n",
    "y_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "13ece251-ba0c-48df-8a51-897063111dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeeze process\n",
    "y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfff4be2-32e3-4421-a5d7-f1a69b1dc418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c780896a-cb74-44ec-a526-f5389a82e0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15b0191b-ad87-4455-9737-c94c544a89c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unsqueeze process\n",
    "y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4a1acd2-525f-4108-a315-42e8d87a9e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5., 2., 3., 4., 5., 6., 7., 8., 9.]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1841a26b-5100-4556-b836-508c5aac71c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 9])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b85e3c00-149d-4f16-a00d-fbb924aaf59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#permute\n",
    "y_original = torch.rand(size=(1,2,3))\n",
    "y_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2146129c-cb45-48b9-8eac-e69f65def29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permute return a view of the original tensor\n",
    "y_permuted = y_original.permute(2, 0, 1)\n",
    "y_permuted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092ff25-d4d9-48da-b66b-a7d13963fec7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Selecting data from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "230e3141-c221-48df-b91a-d6cab2b3dcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing\n",
    "\n",
    "x_indexing = torch.arange(1,10).reshape(1,3,3)\n",
    "x_indexing , x_indexing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03e97c2e-f952-4bb1-b9d0-4fe6384b8570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_indexing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "517afc36-5188-4b05-9caf-6e1751a3d1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_indexing[0, 0] , x_indexing[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b1981b2-d9e9-412c-b090-d61c8a2396bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 7])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MIND BLOWING PQPQ ENTENDI COMO FAZ ESSA MERDA CARALHOW\n",
    "x_indexing[0, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deaee84-da4d-470f-85fb-2184588757e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### PyTorch and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e5f62a2-91fc-4c6f-92f8-3e2b31fc61c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64, torch.float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float types\n",
    "arrayFloat = np.arange(1.0,11.0)\n",
    "tensorFloat = torch.from_numpy(arrayFloat)\n",
    "arrayFloat.dtype , tensorFloat.dtype , torch.arange(1.0, 11.0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dbfdcb93-2e9c-4a7c-a52e-a9f50c198b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, dtype('float32'))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor.dtype , numpy_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc81ae-eec7-4238-8772-b55f15db4779",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Reproducibility\n",
    "\n",
    "*reduce the randomness in NN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "afd5cfc8-9e2b-4be1-a285-a62950815583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9082, 0.6833, 0.6709, 0.5713],\n",
      "        [0.1188, 0.5893, 0.4850, 0.1518],\n",
      "        [0.8522, 0.3161, 0.9609, 0.3173]])\n",
      "tensor([[0.9795, 0.1339, 0.2726, 0.3415],\n",
      "        [0.3548, 0.8552, 0.5909, 0.9315],\n",
      "        [0.5125, 0.7421, 0.5282, 0.1970]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ae52c901-a8f6-4fff-9185-642192dda622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# se quiser reproduzir a mesma aleatoriedade sempre setar a manual_seed\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8811d76c-0b7a-4395-b04e-82a166e46372",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Ways to access a GPU in PyTorch\n",
    "1. Use Google Colab for a free GPU\n",
    "2. Use your own GPU \n",
    "3. Use cloud computing - GCP, AWS, Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9341032e-9437-43bf-b648-36839a851738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Use Google Colab for a free GPU\n",
    "\n",
    "\n",
    "# set the configuration of google colab for using a GPU\n",
    "# then use this command \n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "75d41787-b6cc-4216-8258-df44c30261a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 Use your own GPU \n",
    "\n",
    "\n",
    "# after the setup steps, to check if you are able to use the GPU\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# count the number of devices avaiable\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "32bcdaa8-4a20-45ae-a762-3bb8363fe675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "print(tensor,tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1980f627-6f93-4d0e-8193-1c54ac2c2c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "27ddf79a-a492-41ff-bc81-f1babff5e188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d3bfa8-d243-4513-a418-b1dedf40dad5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "639b9486-ee00-492e-9fc8-1211e86d7c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da10ef30-867d-442b-a66f-2ce0625c70f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor ** 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d6b83952-e731-4cd3-8b36-ad3367123f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 3.1623, 4.4721, 5.4772, 6.3246, 7.0711, 7.7460, 8.3666, 8.9443,\n",
       "         9.4868]),\n",
       " tensor([0.0000, 3.1623, 4.4721, 5.4772, 6.3246, 7.0711, 7.7460, 8.3666, 8.9443,\n",
       "         9.4868]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(x) , x.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "250409e2-8720-4d7b-ad8e-44eeed2b30d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(40), tensor(40))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.median(x) , x.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a9d2b3fd-5155-4d06-8f61-1bcd944811f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(30.2765), tensor(30.2765))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(x.type(torch.float32)) , x.type(torch.float32).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a7ec5f97-281e-4168-a5d5-c6dc38b8e3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int32'), torch.int32, torch.int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int types\n",
    "arrayInt = np.arange(1,11)\n",
    "tensorInt = torch.from_numpy(arrayInt)\n",
    "arrayInt.dtype , tensorInt.dtype , torch.arange(1, 11).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "54df58ee-16f9-48a2-9a99-7bf6c111a8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.int64 torch.int64 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(torch.from_numpy(arrayFloat).type(torch.float32).dtype ,\n",
    "torch.from_numpy(arrayInt).type(torch.int64).dtype ,\n",
    "torch.from_numpy(arrayFloat).type(torch.int64).dtype ,\n",
    "torch.from_numpy(arrayInt).type(torch.float32).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13afc9a-80c6-4801-a496-4d3b498467a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a825cf6-af47-47b4-b14c-e2996845fb43",
   "metadata": {},
   "source": [
    "Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ddeb8-d4cd-45e7-a6ff-20ebc54ba5f8",
   "metadata": {},
   "source": [
    "The two rules of matrix multiplication:\n",
    "1. The **inner dimensions** must match (tá ligado né multiplica coluna com linha tem que ter o mesmo número)\n",
    "2. The resulting matrix has the shape of the"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154cee8b-5930-4056-a900-7caf13998ad8",
   "metadata": {},
   "source": [
    "For floats:\n",
    "1. The default type of *Numpy* is float64\n",
    "2. the default type of *PyTorch* is float32\n",
    "\n",
    "For integers:\n",
    "1. The default type of *Numpy* is int32\n",
    "2. the default type of *PyTorch* is int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e996af8-4d47-4157-893f-642a007a14cf",
   "metadata": {},
   "source": [
    "Tensors on GPU can't be converted to numpy, because numpy uses only cpu's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4f685-68b9-401d-ba92-0915b915c47a",
   "metadata": {},
   "source": [
    "#### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292b5ff-6f87-42e6-9d22-d1af280c698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 ler a documentação, jóia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "240779a4-74c8-4f7a-90c7-173fec89b330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8694, 0.5677, 0.7411, 0.4294, 0.8854, 0.5739, 0.2666],\n",
       "        [0.6274, 0.2696, 0.4414, 0.2969, 0.8317, 0.1053, 0.2695],\n",
       "        [0.3588, 0.1994, 0.5472, 0.0062, 0.9516, 0.0753, 0.8860],\n",
       "        [0.5832, 0.3376, 0.8090, 0.5779, 0.9040, 0.5547, 0.3423],\n",
       "        [0.6343, 0.3644, 0.7104, 0.9464, 0.7890, 0.2814, 0.7886],\n",
       "        [0.5895, 0.7539, 0.1952, 0.0050, 0.3068, 0.1165, 0.9103],\n",
       "        [0.6440, 0.7071, 0.6581, 0.4913, 0.8913, 0.1447, 0.5315]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 \n",
    "random_tensor = torch.rand(7,7)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bf0224a7-914a-4c94-90b1-1a1165e9853e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7081, 1.0097, 2.0143, 1.4687, 2.6574, 0.8652, 2.0333]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "torch.rand(1,7).mm(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0c3a6afe-83e5-4e85-a291-9e9d6e46df07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901],\n",
      "        [0.8964, 0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n",
      "        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823, 0.6816],\n",
      "        [0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527, 0.0362],\n",
      "        [0.1852, 0.3734, 0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
      "        [0.0317, 0.2081, 0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
      "        [0.5846, 0.0332, 0.1387, 0.2422, 0.8155, 0.7932, 0.2783]])\n",
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.4453, 1.0926, 1.4581, 1.3235, 1.4729, 1.2880, 0.7752]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor = torch.rand(7,7)\n",
    "print(random_tensor)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "new_random_tensor = torch.rand(1,7)\n",
    "print(new_random_tensor)\n",
    "\n",
    "new_random_tensor.mm(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "17301310-a576-4476-8df2-cb4a6f436607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "torch.cuda.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0dce01e3-3be6-4a1c-bca8-39d7728d66df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "RANDOM_SEED = 1234\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_A = torch.rand(2,3).to(device)\n",
    "\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_B = torch.rand(2,3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "750423a7-db5d-4cc9-9f0c-9bf57531cdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2299, 0.2161],\n",
       "        [0.2161, 0.6287]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor = random_tensor_A.mm(random_tensor_B.T)\n",
    "output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "02dd644d-1776-44a2-9db5-be4a73c54a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6287), tensor(0.2161))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor.max() , output_tensor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "275ea7d7-03ee-4331-b3df-07e6902f4cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3), tensor(1))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor.argmax() , output_tensor.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "edb937de-1aa0-4689-a31a-70213f4f2ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
      "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
      "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
      "        0.8513]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 7\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor = torch.rand(1,1,1,10)\n",
    "ranodom_tensor_right_dimensions = random_tensor.squeeze()\n",
    "print(random_tensor , random_tensor.shape)\n",
    "\n",
    "print(ranodom_tensor_right_dimensions , ranodom_tensor_right_dimensions.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
